align_metric               : mcs
batch_size                 : 128
dataset                    : aids700nef
dataset_dzh                : dataset1_BA_60
dataset_version            : None
debug                      : False
device                     : cpu
dos_pred                   : sim
dos_true                   : dist
draw_sub_graph             : False
ds_kernel                  : exp
ds_norm                    : True
edge_feats                 : None
filter_large_size          : None
hard_mask                  : True
hostname                   : 8bf587d9bf6e
layer_1                    : NodeEmbedding:type=gcn,output_dim=64,act=relu,bn=True
layer_2                    : NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True
layer_3                    : NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True
layer_4                    : AVG_Pooling:input_dim=64,end_pooling=False,max_pooling=False
layer_5                    : NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True
layer_6                    : NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True
layer_7                    : NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True
layer_8                    : AVG_Pooling:input_dim=64,end_pooling=True,max_pooling=False
layer_num                  : 8
load_model                 : None
lr                         : 0.001
model                      : GCN-Mean
model_name                 : fancy
n_outputs                  : 10
no_probability             : False
node_fe_1                  : one_hot
node_feats                 : type
node_ordering              : bfs
num_epochs                 : None
num_iters                  : 500
num_node_feat              : 30
num_partitions             : 3
num_select                 : 3
only_iters_for_debug       : None
positional_encoding        : False
print_every_iters          : 10
save_every_epochs          : 1
save_model                 : True
save_sub_graph             : False
select_node_pair           : None
sub_graph_path             : ../../sub_graph/
theta                      : 0.5
throw_away                 : 0
traditional_method         : True
train_test_ratio           : 0.8
tvt_options                : all
tvt_strategy               : holdout
user                       : root
validation                 : False
ts                         : 2020-05-03T05-42-48.916612

python /test/graph_up/GraphMatching_submission/model/OurGED/main.py --align_metric=mcs  --batch_size=128  --dataset=aids700nef  --dataset_dzh=dataset1_BA_60  --dataset_version=None  --debug=False  --device=cpu  --dos_pred=sim  --dos_true=dist  --draw_sub_graph=False  --ds_kernel=exp  --ds_norm=True  --edge_feats=None  --filter_large_size=None  --hard_mask=True  --hostname=8bf587d9bf6e  --layer_1=NodeEmbedding:type=gcn,output_dim=64,act=relu,bn=True  --layer_2=NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True  --layer_3=NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True  --layer_4=AVG_Pooling:input_dim=64,end_pooling=False,max_pooling=False  --layer_5=NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True  --layer_6=NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True  --layer_7=NodeEmbedding:type=gcn,input_dim=64,output_dim=64,act=relu,bn=True  --layer_8=AVG_Pooling:input_dim=64,end_pooling=True,max_pooling=False  --layer_num=8  --load_model=None  --lr=0.001  --model=GCN-Mean  --model_name=fancy  --n_outputs=10  --no_probability=False  --node_fe_1=one_hot  --node_feats=type  --node_ordering=bfs  --num_epochs=None  --num_iters=500  --num_node_feat=30  --num_partitions=3  --num_select=3  --only_iters_for_debug=None  --positional_encoding=False  --print_every_iters=10  --save_every_epochs=1  --save_model=True  --save_sub_graph=False  --select_node_pair=None  --sub_graph_path=../../sub_graph/  --theta=0.5  --throw_away=0  --traditional_method=True  --train_test_ratio=0.8  --tvt_options=all  --tvt_strategy=holdout  --user=root  --validation=False

Model(
  (layers): ModuleList(
    (0): NodeEmbedding(
      (conv): GCNConv(30, 64)
      (act): ReLU()
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): NodeEmbedding(
      (conv): GCNConv(64, 64)
      (act): ReLU()
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): NodeEmbedding(
      (conv): GCNConv(64, 64)
      (act): ReLU()
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): Max_AVG_Pooling_Layer(
      (conv): GCNConv(64, 64)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (MLP_1): Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): ReLU()
      )
      (relu): ReLU()
      (MLP_3): Sequential(
        (0): Linear(in_features=32, out_features=512, bias=True)
        (1): ReLU()
      )
      (similarity_compute): CosineSimilarity()
      (criterion): MSELoss()
    )
    (4): NodeEmbedding(
      (conv): GCNConv(64, 64)
      (act): ReLU()
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): NodeEmbedding(
      (conv): GCNConv(64, 64)
      (act): ReLU()
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): NodeEmbedding(
      (conv): GCNConv(64, 64)
      (act): ReLU()
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): Max_AVG_Pooling_Layer(
      (conv): GCNConv(64, 64)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (MLP_1): Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): ReLU()
      )
      (relu): ReLU()
      (MLP_3): Sequential(
        (0): Linear(in_features=32, out_features=512, bias=True)
        (1): ReLU()
      )
      (similarity_compute): CosineSimilarity()
      (criterion): MSELoss()
    )
  )
  (criterion): MSELoss()
  (GNN_1): NodeEmbedding(
    (conv): GINConv(nn=Sequential(
      (0): Linear(in_features=30, out_features=64, bias=True)
      (1): PReLU(num_parameters=64)
      (2): Linear(in_features=64, out_features=64, bias=True)
    ))
    (act): PReLU(num_parameters=64)
    (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (GNN_2): NodeEmbedding(
    (conv): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): PReLU(num_parameters=32)
      (2): Linear(in_features=32, out_features=32, bias=True)
    ))
    (act): PReLU(num_parameters=32)
    (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (GNN_3): NodeEmbedding(
    (conv): GINConv(nn=Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): PReLU(num_parameters=16)
      (2): Linear(in_features=16, out_features=16, bias=True)
    ))
    (act): PReLU(num_parameters=16)
    (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (ntn_layer): NTN(
    (inneract): ReLU()
  )
  (graph_mlp_layers): ModuleList(
    (0): Linear(in_features=16, out_features=8, bias=False)
    (1): Sigmoid()
    (2): Linear(in_features=8, out_features=4, bias=False)
    (3): Sigmoid()
    (4): Linear(in_features=4, out_features=2, bias=False)
    (5): Sigmoid()
    (6): Linear(in_features=2, out_features=1, bias=False)
  )
)
